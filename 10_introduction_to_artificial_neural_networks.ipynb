{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks\n",
    "1. **인공신경망(ANN)** 구조 이해\n",
    "2. **다층 퍼셉트론(MLPs: Multi-Layer Perceptrons)** 을 TensorFlow로 구현하고 MNIST 분류 문제를 풀어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifcial Neural Netorks(ANNs)\n",
    "> - 기원은 뇌의 구조\n",
    "> - 자연을 본따는 인간의 습성이 그러하듯 \n",
    "> - 하지만 창의성을 위해서는 생물학적 사고 안에서 머물러서는 안된다.\n",
    "> - ANNs는 Deep Learning의 핵심이다.\n",
    "> - 다재다능/강력/확장성으로 어려운 머신러닝 숙제를 잘 풀어간다. (이미지 분류, 음성인식, 추천시스템, 게임)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ANNs 는 출현한지 좀 오래된 알고리즘\n",
    " - 1943 신경생리학자 Warren McCulloch와 수학자 Walter Pitts \"A Logical Calculus of Ideas Immanent in Nervous Activity\"\n",
    "   - **논리연산을 사용한 복잡한 계산을 수행시, 동물 두뇌에서 생물학적 뉴런이 작동하는 단순화된 계산 모델 제시** ← 최초 ann 구조\n",
    " - 이후 다른 구조들이 발명되었음\n",
    "\n",
    "\n",
    "- 1960년대까지 ANN 초기 성공은 지능이 있는 기계와 대화할거라는 믿음을 이끌어냈다.\n",
    "- 80년대 초반까지는 암흑기(펀딩x), 새로운 구조와 학습 기술이 개발되면서 다시 관심이 생겨남\n",
    "- 90년대에는 SVM에 밀림(결과가 좋고 이론적 기초가 탄탄)\n",
    "- 최근에는...\n",
    " - <font color='red'>데이터</font>가 방대함, 다른 ML 테크닉보다 크고 복잡한 문제에 성능이 더 좋음\n",
    " - 1990 년대 이후로 <font color='red'>컴퓨팅 파워(GPU, 게임 업계 덕분)</font>가 엄청나게 개선된 덕분에 합리적인 시간에 대규모 신경 네트워크를 학습 할 수 있음\n",
    " - <font color='red'>학습 알고리즘이 개선</font>되었습니다. 사실 그들은 1990 년대에 사용 된 것들과 약간만 다르지만, 이런 작은 비틀기는 엄청난 긍정적 영향을 미침\n",
    " - ANN의 이론적 한계중 일부가 현업에서 쓰기에 무리가 없음이 밝혀짐\n",
    "   - **ex) ANN 교육 알고리즘이 Local 최적 상태에 머물러 있기 때문에 한계에 부딪혔다 고 생각하지만 실제로는 현업에서 그럴일이 거의 없음 \n",
    "   (또는 실제로 그런 경우 일반적으로 Global 최적에 가까움).**\n",
    " - ANN은 자금 조달 및 진보의 선순환 들어갔다. 헤드라인 뉴스 제조기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Neurons\n",
    "> 고차원의 복잡한 계산이 단순한 뉴론들의 Multi layers로 수행될 수 있다. Biological 뉴런 네트워크의 The architecture은 여전히 핫한 연구 주제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Computations with Neurons\n",
    "(assuming that a neuron is activated when at least two of its inputs are active)\n",
    " <img src=\"./book_img/ch10/10_p1.SimpleANN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 간단한 ANN 구조 by 1957 Frank Rosenblatt\n",
    " - linear threshold unit(LTU) : 이진 분류에 사용 (just like a Logistic Regression classifier or a linear SVM) \n",
    "   - input&ouput: numbers (not binary on/off values)\n",
    "   - 각 입력연결은 가중치와 연결된다.\n",
    "   - 입력갑들의 합들을 계산하고, 그 합을 임계값을 경계로 출력하는 2단계로 처리\n",
    "   \n",
    "\n",
    "- Perceptron은 단일 LTU로 구성되어 있다.\n",
    " - input neurons\n",
    " - bias neuron\n",
    "   \n",
    "`\"퍼셉트론에서는 활성화 함수로 계단 함수를 이용한다\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p2.LTU.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p2_2.perceptron_diagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Heaviside Step Function(계단함수) 과 부호함수(sign function)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p3.StepFunction.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Percpetron 학습 방법\n",
    " - training algorithm은 Hebb's rule에 영감을 받은 Frank Rosenblatt 에 의해 제안됨\n",
    "   - \"어떤 신경세포의 활성이 다른 신경세포가 활성하는데 계속적으로 공헌을 한다면, 두 신경세포 간의 연결 가중치를 증가시켜 주어야 한다.\"\n",
    "   __ The Organization of Behavior, 1949, Donald Hebb ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p4.Perceptron learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 각 ouput neuron 의 decision boundary 가 선형이므로, perceptron은 복잡한 패턴을 학습하는데 한계가 있다. (Logistic Regression calssifier 처럼)\n",
    "- 하지만 training instances가 선형으로 분리가능하다면, 이 알고리즘이 해로 수렴함: *Percpetron convergence theorem*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Boolean -> integer\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron 학습 알고리즘은 Stochastic Gradient Descent와 유사하다.\n",
    "- Scikit-Learn's Perceptron 클래스는 SGDClassifier 의 아래 하이퍼파라미터 설정으로 했을때 동일하다.\n",
    " - *loss = \"perceptron\", learning_rate=\"constant\", eta0=1 (the learning rate), penalty = None (no regularization)* ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression classifiers과 다르게, 각 클래스의 확률을 출력하지 않고 hard threshold에 기반한 예측만 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론의 약점을 기술한 Monograph(Perceptrons, Marvin Minsky and Seymour Papert, 1969)\n",
    " - Exclusive OR(XOR) 문제 못푼다.이는 다른 선형 분류기도 마찬가지만, 많은 연구자들이 connectionism 을 포기하는 계기가 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이러한 한계점은 여러 Perceptrons 들을 쌓으면서 해소될 수 있다.\n",
    "- 이 ANN은 Multi-Layer Perceptron(MLP)라 불린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p5.XOR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLP 는 (passthrough) input layer과, 1개 이상의 LTU (hidden layers), 마지막 ouput layer로 구성되어 있다.\n",
    " - ouput layer를 제외한 모든 레이어에 bias neuron이 있고, 다음 레이어에 fully connected 되어 있다.\n",
    " - hidden layers가 2개 이상이라면 Deep nural network(DNN)라고 불린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p6.MLP.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 해 동안 MLP를 학습시키기 위해 많은 연구자들이 성과 없이 고군분투 했다.\n",
    "- <font color = red>**backpropagation** 학습 알고리즘</font>을 소개하는 \"Learning Internal Represenations by Error Propagation\"(1986, D.E. Rumelhar et al) 획기적인 논문이 발간되었다.\n",
    "- 오늘날 우리가 이야기하는**reverse-mode autodiff를 이용한 Gradient Descent 이다.**\n",
    " > 개별 학습 instacne 마다... 모든 누적 레이어에 대해 feed forward pass 이후에 ouput error를 보고, 마지막 hidden layer의 각 뉴런이 ouput error에 얼마나 기여를 했는지 계산한다. 후에 input layer까지 각 이전 hidden layer에서 에러 기여도를 측정하는 방법\n",
    "   - 이러한 reverse pass(**<font color=red>error gradient</font>를 네트워크에서 역으로 전파**함으로써)는 네트워크의 모든 연결된 weight에 대해 error gradient를 효과적으로 측정한다.\n",
    "   - 역전파(backpropatation) 알고리즘의 마지막 단계는 앞에서 측정 한 오류 기울기(error gradient)를 사용하여 네트워크의 모든 연결 가중치에 대한 Gradient Descent 을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, ` \"예측을 하고(forward pass), 에러를 측정하고, 개별 layer를 역으로 추적해 나가면서 각 연결의 error contribution를 계산한다(reverse pass). 그리고 에러를 줄이는 방향으로 가중치를 조정한다(Gradient Descent).\" `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 알고리즘이 **제대로 작동하기 위한 핵심(key change)은 step function 대신에 logistic function을 적용하는 MLP's 구조**이다.\n",
    " > logistic function이 모든 곳에서 잘정의된(0이 아닌) 미분계수를 구해주고, 이를 통해 Gradient Descent를 각 단계마다 성공적으로 진전시킬수 있다.\n",
    " > logistic function 대신에 다른 activation function을 적용할수도 있다.\n",
    "   - *The hyperbolic tangent function*\n",
    "    : 1~1(logistic functoin: 0 ~ 1) / normalized(helps speed up convergence)\n",
    "   - *The ReLU function*\n",
    "     : ReLU (z) = max(0, z): 연속적이지만 미분가능하지 않다.(기울기가 급격히 변해서 경사하강이 잘 안된다) / 실제로는 계산이 빠른 이점이 있다. 가장 중요한 것은 출력 값이 최대치가 아니기 때문에 경사하강 중 일부 문제를 줄일 수 있다는 것입니다. ☆\n",
    "   \n",
    "  - 생물학적 뉴런은 활성화 함수를 시그모이드(S-자) 를 구현한다. 따라서 이를 오랫동안 고수했지만, ANN에서 ReLU가 더 잘 작동하는 것이 발견되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, 5, -0.2, 1.2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApsAAAEMCAYAAACLGX0CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm0IIIYQQwm3+H290WQ+HGmvQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2168f0e72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "# save_fig(\"activation_functions_plot\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLP는 이진 분류기(스팸, 긴급 알림 등)에 자주 쓰인다.\n",
    "- 결과가 배타적이라면(이지 분류가 0~9까지 잇을때 등) output layer를 individual activation function 이 아닌 shared soft-max 함수를 적용하면 된다.\n",
    " - 각 뉴런의 출력은 해당 클래스의 예상 확률에 해당한다.\n",
    "\n",
    "Note that the signal flows only in one direction (from the inputs to the outputs), so this architecture is an example of a feedforward neural network ☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./book_img/ch10/10_p7.MLP_wSpftmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAEMCAYAAACfoCGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREpIAU0kREREQKSCFNREREpID+D69kOaK5eDcGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2168f2af630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an MLP with TensorFlow's High-Level API\n",
    "## using tf.learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF.Learn의 DNN Classifier 클래스는 hidden layer 와 softmax output layer을 쉽게 만들어준다.\n",
    "- (예제) DNN 2개 hiedden layers(각각 300개, 100개 뉴런)과 1개의 output layer (10개 뉴런) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZOYI\\AppData\\Local\\Temp\\tmpz08o02jh\n",
      "INFO:tensorflow:Using config: {'_master': '', '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000216948FC630>, '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_session_config': None, '_save_summary_steps': 100, '_model_dir': 'C:\\\\Users\\\\ZOYI\\\\AppData\\\\Local\\\\Temp\\\\tmpz08o02jh', '_environment': 'local', '_evaluation_master': '', '_task_id': 0, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 42, '_task_type': None, '_num_worker_replicas': 0, '_save_checkpoints_steps': None}\n",
      "WARNING:tensorflow:From C:\\Users\\ZOYI\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZOYI\\AppData\\Local\\Temp\\tmpz08o02jh\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.36404, step = 1\n",
      "INFO:tensorflow:global_step/sec: 204.989\n",
      "INFO:tensorflow:loss = 0.311432, step = 101 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.301\n",
      "INFO:tensorflow:loss = 0.265409, step = 201 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.196\n",
      "INFO:tensorflow:loss = 0.408733, step = 301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.004\n",
      "INFO:tensorflow:loss = 0.244357, step = 401 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.335\n",
      "INFO:tensorflow:loss = 0.238858, step = 501 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.01\n",
      "INFO:tensorflow:loss = 0.091827, step = 601 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.48\n",
      "INFO:tensorflow:loss = 0.123374, step = 701 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.415\n",
      "INFO:tensorflow:loss = 0.196473, step = 801 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.446\n",
      "INFO:tensorflow:loss = 0.0932024, step = 901 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.169\n",
      "INFO:tensorflow:loss = 0.196834, step = 1001 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.378\n",
      "INFO:tensorflow:loss = 0.194408, step = 1101 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.178\n",
      "INFO:tensorflow:loss = 0.152048, step = 1201 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.34\n",
      "INFO:tensorflow:loss = 0.149761, step = 1301 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.622\n",
      "INFO:tensorflow:loss = 0.0647763, step = 1401 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.099\n",
      "INFO:tensorflow:loss = 0.0727728, step = 1501 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.758\n",
      "INFO:tensorflow:loss = 0.120371, step = 1601 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.57\n",
      "INFO:tensorflow:loss = 0.0426907, step = 1701 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.283\n",
      "INFO:tensorflow:loss = 0.148324, step = 1801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.44\n",
      "INFO:tensorflow:loss = 0.073107, step = 1901 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.489\n",
      "INFO:tensorflow:loss = 0.0638611, step = 2001 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.386\n",
      "INFO:tensorflow:loss = 0.0233887, step = 2101 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.123\n",
      "INFO:tensorflow:loss = 0.0329285, step = 2201 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.203\n",
      "INFO:tensorflow:loss = 0.0519914, step = 2301 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.424\n",
      "INFO:tensorflow:loss = 0.0577268, step = 2401 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.602\n",
      "INFO:tensorflow:loss = 0.084227, step = 2501 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.022\n",
      "INFO:tensorflow:loss = 0.0315869, step = 2601 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.155\n",
      "INFO:tensorflow:loss = 0.0121763, step = 2701 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.655\n",
      "INFO:tensorflow:loss = 0.0630663, step = 2801 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.94\n",
      "INFO:tensorflow:loss = 0.0913481, step = 2901 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.551\n",
      "INFO:tensorflow:loss = 0.0138151, step = 3001 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.158\n",
      "INFO:tensorflow:loss = 0.0337465, step = 3101 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.239\n",
      "INFO:tensorflow:loss = 0.0132512, step = 3201 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.384\n",
      "INFO:tensorflow:loss = 0.0321816, step = 3301 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.143895, step = 3401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.855\n",
      "INFO:tensorflow:loss = 0.0897496, step = 3501 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.648\n",
      "INFO:tensorflow:loss = 0.157295, step = 3601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.577\n",
      "INFO:tensorflow:loss = 0.03669, step = 3701 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.953\n",
      "INFO:tensorflow:loss = 0.0122543, step = 3801 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.267\n",
      "INFO:tensorflow:loss = 0.152421, step = 3901 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.737\n",
      "INFO:tensorflow:loss = 0.107787, step = 4001 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.212\n",
      "INFO:tensorflow:loss = 0.0485792, step = 4101 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0590532, step = 4201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.438\n",
      "INFO:tensorflow:loss = 0.158572, step = 4301 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.172\n",
      "INFO:tensorflow:loss = 0.114563, step = 4401 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.673\n",
      "INFO:tensorflow:loss = 0.0187132, step = 4501 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.428\n",
      "INFO:tensorflow:loss = 0.0182185, step = 4601 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.358\n",
      "INFO:tensorflow:loss = 0.00904818, step = 4701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.0186206, step = 4801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.0834735, step = 4901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.038\n",
      "INFO:tensorflow:loss = 0.0451745, step = 5001 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00802126, step = 5101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.0236921, step = 5201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.448\n",
      "INFO:tensorflow:loss = 0.040991, step = 5301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0607277, step = 5401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0441553, step = 5501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0769239, step = 5601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.0198653, step = 5701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.251\n",
      "INFO:tensorflow:loss = 0.00881232, step = 5801 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.110585, step = 5901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0857567, step = 6001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.074\n",
      "INFO:tensorflow:loss = 0.0120617, step = 6101 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.634\n",
      "INFO:tensorflow:loss = 0.022921, step = 6201 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.304\n",
      "INFO:tensorflow:loss = 0.0707142, step = 6301 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.0212568, step = 6401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00796753, step = 6501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.854\n",
      "INFO:tensorflow:loss = 0.0281497, step = 6601 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0216029, step = 6701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0129809, step = 6801 (0.484 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 193.936\n",
      "INFO:tensorflow:loss = 0.0126797, step = 6901 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.0166421, step = 7001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00448675, step = 7101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0508161, step = 7201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.268\n",
      "INFO:tensorflow:loss = 0.00550252, step = 7301 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.0154965, step = 7401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.004822, step = 7501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0131625, step = 7601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00680886, step = 7701 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.937\n",
      "INFO:tensorflow:loss = 0.00376618, step = 7801 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0131479, step = 7901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00631671, step = 8001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0245089, step = 8101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.0208505, step = 8201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.448\n",
      "INFO:tensorflow:loss = 0.04197, step = 8301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.0136715, step = 8401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0110502, step = 8501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00604934, step = 8601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0065747, step = 8701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00738027, step = 8801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00280681, step = 8901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.015022, step = 9001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00840854, step = 9101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00372718, step = 9201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.0134235, step = 9301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.034022, step = 9401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00841827, step = 9501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.015819, step = 9601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.0086599, step = 9701 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00439482, step = 9801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.0174038, step = 9901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0208312, step = 10001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00381713, step = 10101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00676587, step = 10201 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00574352, step = 10301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00939435, step = 10401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00275532, step = 10501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00952128, step = 10601 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0303758, step = 10701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.0115768, step = 10801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00465772, step = 10901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.0293584, step = 11001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00492727, step = 11101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000853527, step = 11201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0139262, step = 11301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00881559, step = 11401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0186049, step = 11501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000492324, step = 11601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00230341, step = 11701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000418936, step = 11801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00709947, step = 11901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000176346, step = 12001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00352114, step = 12101 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00409825, step = 12201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00442711, step = 12301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000686727, step = 12401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00342111, step = 12501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00143894, step = 12601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00396524, step = 12701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00715362, step = 12801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00564594, step = 12901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00317152, step = 13001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00411803, step = 13101 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00683057, step = 13201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00482892, step = 13301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.567\n",
      "INFO:tensorflow:loss = 0.00194253, step = 13401 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00725991, step = 13501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00496594, step = 13601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00231069, step = 13701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00758488, step = 13801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00351695, step = 13901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00250569, step = 14001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00576778, step = 14101 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0106178, step = 14201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.936\n",
      "INFO:tensorflow:loss = 0.00184563, step = 14301 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.688\n",
      "INFO:tensorflow:loss = 0.000657787, step = 14401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000907568, step = 14501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00308903, step = 14601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000958802, step = 14701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.329\n",
      "INFO:tensorflow:loss = 0.00119474, step = 14801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00213329, step = 14901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0011101, step = 15001 (0.469 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00242632, step = 15101 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00159225, step = 15201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.0014488, step = 15301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.275\n",
      "INFO:tensorflow:loss = 0.00376972, step = 15401 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00406733, step = 15501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00472252, step = 15601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0146699, step = 15701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00153426, step = 15801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000447847, step = 15901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00656253, step = 16001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.0043496, step = 16101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 7.70298e-05, step = 16201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00260926, step = 16301 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00155471, step = 16401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0015937, step = 16501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00472044, step = 16601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00249327, step = 16701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.982\n",
      "INFO:tensorflow:loss = 0.00237052, step = 16801 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00251921, step = 16901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00285329, step = 17001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.000563493, step = 17101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00264452, step = 17201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000915113, step = 17301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00186997, step = 17401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00155757, step = 17501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000356618, step = 17601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.257\n",
      "INFO:tensorflow:loss = 0.000703532, step = 17701 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000502199, step = 17801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00201421, step = 17901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.00172619, step = 18001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000986052, step = 18101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.00447541, step = 18201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0146146, step = 18301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00289675, step = 18401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.0022742, step = 18501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00423942, step = 18601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000945454, step = 18701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00149365, step = 18801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.688\n",
      "INFO:tensorflow:loss = 0.00309862, step = 18901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00134573, step = 19001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000693691, step = 19101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000465131, step = 19201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00558755, step = 19301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000528183, step = 19401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00208042, step = 19501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000694155, step = 19601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000119371, step = 19701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.571\n",
      "INFO:tensorflow:loss = 0.00051242, step = 19801 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00184305, step = 19901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00206445, step = 20001 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.0003063, step = 20101 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.36\n",
      "INFO:tensorflow:loss = 0.00195141, step = 20201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000959544, step = 20301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00013434, step = 20401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.0003517, step = 20501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00149112, step = 20601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00112818, step = 20701 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00154887, step = 20801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00139391, step = 20901 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00281828, step = 21001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.08\n",
      "INFO:tensorflow:loss = 0.00136329, step = 21101 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00240587, step = 21201 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00113844, step = 21301 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00262636, step = 21401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000237559, step = 21501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00151222, step = 21601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000995086, step = 21701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000349444, step = 21801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.458\n",
      "INFO:tensorflow:loss = 0.000656097, step = 21901 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000148364, step = 22001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.448\n",
      "INFO:tensorflow:loss = 0.000531831, step = 22101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00140872, step = 22201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00243447, step = 22301 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00220339, step = 22401 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00157356, step = 22501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.937\n",
      "INFO:tensorflow:loss = 0.00364198, step = 22601 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.000852597, step = 22701 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.233\n",
      "INFO:tensorflow:loss = 0.00109362, step = 22801 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.00240539, step = 22901 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 0.000654596, step = 23001 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.937\n",
      "INFO:tensorflow:loss = 0.00295467, step = 23101 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00217089, step = 23201 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00169613, step = 23301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000720154, step = 23401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000805685, step = 23501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000631053, step = 23601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000255326, step = 23701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00180432, step = 23801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000976085, step = 23901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00113664, step = 24001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.364\n",
      "INFO:tensorflow:loss = 0.000741892, step = 24101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000928554, step = 24201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000218442, step = 24301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00173174, step = 24401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000569286, step = 24501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000322807, step = 24601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00111121, step = 24701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00132868, step = 24801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00235335, step = 24901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.329\n",
      "INFO:tensorflow:loss = 0.000118122, step = 25001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00184492, step = 25101 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.685\n",
      "INFO:tensorflow:loss = 0.00320799, step = 25201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.688\n",
      "INFO:tensorflow:loss = 0.000183373, step = 25301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000734714, step = 25401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.00117328, step = 25501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00101388, step = 25601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000994076, step = 25701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00148109, step = 25801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00150336, step = 25901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 4.42679e-05, step = 26001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000945769, step = 26101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000692925, step = 26201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000701611, step = 26301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.448\n",
      "INFO:tensorflow:loss = 0.00164209, step = 26401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000905918, step = 26501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000519783, step = 26601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 1.40954e-05, step = 26701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000842135, step = 26801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000808341, step = 26901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000642265, step = 27001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000423766, step = 27101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000671817, step = 27201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00108788, step = 27301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000168051, step = 27401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.00143462, step = 27501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000935573, step = 27601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000289417, step = 27701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000623281, step = 27801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000400492, step = 27901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00141883, step = 28001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000513484, step = 28101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00133993, step = 28201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000679669, step = 28301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000811346, step = 28401 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.556\n",
      "INFO:tensorflow:loss = 0.00057602, step = 28501 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000366546, step = 28601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00086157, step = 28701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.307\n",
      "INFO:tensorflow:loss = 0.00103206, step = 28801 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000274243, step = 28901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00182547, step = 29001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00104729, step = 29101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.001766, step = 29201 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00105772, step = 29301 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000961037, step = 29401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.00102937, step = 29501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000430005, step = 29601 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00025649, step = 29701 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000605404, step = 29801 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.792\n",
      "INFO:tensorflow:loss = 0.00077305, step = 29901 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000108064, step = 30001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000590002, step = 30101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000234104, step = 30201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00065963, step = 30301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00115885, step = 30401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000882715, step = 30501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00145138, step = 30601 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.474\n",
      "INFO:tensorflow:loss = 0.000891694, step = 30701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00118, step = 30801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00115266, step = 30901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000961674, step = 31001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00149113, step = 31101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000568497, step = 31201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.000460989, step = 31301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000649023, step = 31401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000197947, step = 31501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 6.59552e-05, step = 31601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000625275, step = 31701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.45\n",
      "INFO:tensorflow:loss = 9.4202e-05, step = 31801 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000756386, step = 31901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000197061, step = 32001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000425281, step = 32101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00102074, step = 32201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.00041044, step = 32301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000104019, step = 32401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000511087, step = 32501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000111053, step = 32601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00126878, step = 32701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000895224, step = 32801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000406547, step = 32901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000497633, step = 33001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.448\n",
      "INFO:tensorflow:loss = 0.00210473, step = 33101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000945465, step = 33201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000309007, step = 33301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00123292, step = 33401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000225348, step = 33501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.329\n",
      "INFO:tensorflow:loss = 0.000940695, step = 33601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000726792, step = 33701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00123973, step = 33801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00107691, step = 33901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000640319, step = 34001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000919945, step = 34101 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00121334, step = 34201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000127433, step = 34301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000417725, step = 34401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000630038, step = 34501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000360699, step = 34601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00173927, step = 34701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000371267, step = 34801 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000374646, step = 34901 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000305932, step = 35001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.711\n",
      "INFO:tensorflow:loss = 0.00104693, step = 35101 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000340343, step = 35201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000153641, step = 35301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000996451, step = 35401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000171532, step = 35501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000374124, step = 35601 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000663798, step = 35701 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.567\n",
      "INFO:tensorflow:loss = 0.000831119, step = 35801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000574592, step = 35901 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000313818, step = 36001 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.567\n",
      "INFO:tensorflow:loss = 0.00114753, step = 36101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.45\n",
      "INFO:tensorflow:loss = 0.000859921, step = 36201 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 9.09132e-05, step = 36301 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.449\n",
      "INFO:tensorflow:loss = 0.000575347, step = 36401 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.64\n",
      "INFO:tensorflow:loss = 0.000190056, step = 36501 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000239809, step = 36601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.168\n",
      "INFO:tensorflow:loss = 0.00044674, step = 36701 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000904511, step = 36801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000720104, step = 36901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000412932, step = 37001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000163695, step = 37101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000264861, step = 37201 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000719457, step = 37301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.368\n",
      "INFO:tensorflow:loss = 0.000339975, step = 37401 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000324403, step = 37501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000306283, step = 37601 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000100169, step = 37701 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000432111, step = 37801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00140533, step = 37901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000294866, step = 38001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.00119604, step = 38101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000891358, step = 38201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000129545, step = 38301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.568\n",
      "INFO:tensorflow:loss = 0.000193591, step = 38401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.447\n",
      "INFO:tensorflow:loss = 0.00049303, step = 38501 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.688\n",
      "INFO:tensorflow:loss = 0.000675174, step = 38601 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000358051, step = 38701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.000242674, step = 38801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.00127899, step = 38901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.331\n",
      "INFO:tensorflow:loss = 0.000262657, step = 39001 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.685\n",
      "INFO:tensorflow:loss = 0.000705544, step = 39101 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000659797, step = 39201 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.000316944, step = 39301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.000639012, step = 39401 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000241011, step = 39501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.686\n",
      "INFO:tensorflow:loss = 0.000744708, step = 39601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.569\n",
      "INFO:tensorflow:loss = 0.000178735, step = 39701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.33\n",
      "INFO:tensorflow:loss = 0.00115475, step = 39801 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.687\n",
      "INFO:tensorflow:loss = 0.00126455, step = 39901 (0.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\ZOYI\\AppData\\Local\\Temp\\tmpz08o02jh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000402969.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZOYI\\AppData\\Local\\Temp\\tmpz08o02jh\\model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98209999999999997"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071960262984114065"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss # to evaluate\n",
    "\n",
    "y_pred_proba = y_pred['probabilities']\n",
    "log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN Using Plain TensorFlow\n",
    "## Using plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Minibatch Gradient Descent 를 이용해 MNIST 데이터를 학습시켜 보자.\n",
    " - Construction phase: building the TensorFlow gratph\n",
    " - Execution phase: actually run the graph to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300 # num. of hidden neurons in each layer\n",
    "n_hidden2 = 100 \n",
    "n_outputs = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- placeholder nodes: trainig data와 target을 나타내자\n",
    " -  batch_size, 입력 형태와 트레이닝 data의 입력 형태를 정의\n",
    " - images_placeholder = tf.placeholder(<kbd>tf.float32</kbd>, shape=(<kbd>batch_size</kbd>, <kbd>mnist.IMAGE_PIXELS</kbd>))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")# represent training data\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\") # represent target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X의 모양은 부분적으로 만 정의된다.\n",
    "- 첫 번째 차원의 인스턴스와 두 번째 차원의 피쳐를 가진 2D 텐서 (즉, 행렬)가 될 것이며, 피쳐의 수는 28 x 28 (픽셀 당 하나의 피쳐)이 될 것이라는 것을 알고 있습니다. 하지만 각 훈련 배치에 몇 개의 인스턴스가 포함되는지는 아직 알 수 없습니다. 그래서 X의 모양은 (None, n_inputs)이다. \n",
    "- 마찬가지로 y는 인스턴스 당 하나의 엔트리를 가진 1D 텐서가되지만이 시점에서 트레이닝 배치의 크기를 알 수 없기 때문에 모양은 (없음)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 실제 신경망을 만들어 보겠습니다. 자리 표시 자 X는 입력 레이어의 역할을 한다.\n",
    "- 실행 단계에서 한 번에 하나의 학습 배치마다 대체됩니다 (학습 배치의 모든 인스턴스는 신경 네트워크에 의해 동시에 처리된다). ☆\n",
    "- 이제 두 개의 숨겨진 레이어와 출력 레이어를 만들자.\n",
    "- 두 개의 숨겨진 레이어는 거의 동일합니다. 연결되어있는 입력과 포함 된 뉴런의 수에 따라 다르다.\n",
    "- 출력 계층도 매우 유사하지만 ReLU 활성화 기능 대신 softmax 활성화 기능을 사용한다. \n",
    "- neuron_layer () 함수를 만들어서 한번에 여러개의 레이어를 만들자. 입력, 뉴런 수, 활성화 함수 및 레이어 이름을 지정하는 매개 변수가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):  # neuron layer를 만드는 함수\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 먼저 레이어의 이름을 사용하여 name scope를 만든다.이 뉴런 레이어에는 필요한 모든 계산 노드가 포함된다. 선택 사항이지만 노드가 잘 구성되어 있으면 그래프가 TensorBoard에서 훨씬 더 멋지게 보입니다. \n",
    "2. 다음으로, 입력 수를 얻는데, 입력 행렬의 모양을 찾아 두 번째 차원의 크기를 가져 온다.  (첫 번째 차원은 인스턴스 용입니다). \n",
    "3. 다음 세 줄은 가중치 행렬을 보유 할 W 변수를 작성한다. 각 입력과 각 뉴런 사이의 모든 연결 가중치를 포함하는 2D 텐서가 된다. 따라서 그 모양은 (n_inputs, n_neurons)가 된다. 표준 편차가 2 / ninputs 인 truncated normal (Gaussian) 분포를 사용하여 무작위로 초기화됩니다. 이 특정 표준 편차를 사용하면 알고리즘이 훨씬 빨리 수렴하는 데 도움이 된다 (이는 신경 네트워크의 효율성에 엄청난 영향을 끼친 작은 조정 중 하나). 경사 하강 알고리즘이 대칭문제를 피하기 위해 모든 숨겨진 레이어에 대해 연결 가중치를 임의로 초기화하는 것이 중요하다 . \n",
    "4. 다음 줄은 0으로 초기화 되는 bias  b 변수를 만듭니다 (여기서는 대칭 문제 없음) 각 뉴런 당 하나의 바이어스 매개 변수가 있다. \n",
    "5. 그런 다음 z = X · W + b를 계산하기 위한 부분 그래프를 만든다. 이 벡터화 된 구현은 배치의 모든 인스턴스에 대해서 레이어와 뉴런 각각 입력의 가중치 합계와 바이어스 합을 효율적으로 계산한다.\n",
    "6. 마지막으로 활성화 매개 변수가 \"relu\"로 설정된 경우 코드에서 relu (z) (즉, max (0, z))를 반환하거나 아니면 z를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):  # deep neural network를 만들자\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",  # 첫번째 hidden layer에서는 X를 input으로 받는다.\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",  # hidden1을 ouput을 input으로 받는다.\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\") # ouput layer에서는 hidden2을 ouput을 input으로 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 명확하게 보기 위해 name scope를 사용했다. \n",
    "- logits는 softmax 활성화 함수를 거치기 전에 신경망의 출력입니다. 최적화를 위해 나중에 softmax 계산은 나중에 처리 할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 우리는 신경망 모델을 사용할 준비가되었습니다. 우리는 이를 훈련시키는 데 사용할 Cost Function을 정의해야 한다.\n",
    "- 교차 엔트로피는 목표 클래스에 대해 낮은 확률로 추정하는 모델에 불이익을 준다. TensorFlow는 교차 엔트로피를 계산하는 몇 가지 기능을 제공하는데, 우리는 `sparse_soft max_cross_entropy_with_logits ()`를 사용한다.\n",
    "- `sparse_soft max_cross_entropy_with_logits ()`: \"logits\"(즉, softmax 활성화 함수를 거치기 전에 네트워크의 출력)를 기반으로 크로스 엔트로피를 계산합니다. 0에서부터 클래스 수 - 1 (우리의 경우 0에서 9)개의 라벨링을 한다. 이것은 각 인스턴스 마다 교차 엔트로피를 포함하는 1D 텐서를 출력한다. 이때 TensorFlow의 `reduce_mean ()` 함수를 사용하여 모든 인스턴스에 대한 평균 교차 엔트로피를 계산할 수 있다.\n",
    "> `sparse_softmax_cross_entropy_with_logits ()` 함수는 softmax 활성화 함수를 적용한 다음 크로스 엔트로피를 계산하는 것과 동일하지만보다 효율적이며 logits = 0 과 같은 사례를 적절하게 처리합니다. 따라서 softmax 활성화를 적용하지 않았다.\n",
    "`softmax_cross_entropy_with_logits ()`라는 또 다른 함수는 이 함수는 one-hot 벡터의 형태로 레이블을 취합니다 (int에서 0에서 클래스 수 빼기 대신)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망모델, 비용함수를 정의했으니, 비용 함수를 최소화하기 위해 모델 매개 변수를 조정할 `GradientDescentOptimizer`을 정의하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구축 단계의 마지막 중요한 단계는 모델 평가 방법을 지정하는 것이다. 여기서는 단순히 성능 척도로서 정확도를 사용한다.\n",
    "- 첫째, 각 인스턴스에 대해 가장 높은 logit 값이 target 클래스에 해당하는지 여부를 확인하여 신경망의 예측이 올바른지 확인한다. \n",
    "- 이를 위해 in_top_k () 함수를 사용하자. 부울 값으로 가득 찬 1D 텐서를 반환하므로써 부울을 부동 소수점 형으로 캐스팅 한 다음 평균을 계산해야한다. 이렇게하면 네트워크의 전체적인 정확성을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평소처럼 모든 변수를 초기화하는 노드를 만들어야하며, 훈련 된 모델 매개 변수를 디스크에 저장하는 `Saver`도 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 및 대상에 대한 place holder을 만들었고, 신경 층을 만드는 함수를 만들고 DNN을 만드는 데 사용했으며, 비용 함수를 정의했다. 최적화 도구를 만들고 마지막으로 성능 측정 값을 정의했습니다. 이제 실행 단계로 넘어가자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST를 로드를(ScikitLearn 대신) TensorFlow로 데이터를 가져 와서 크기를 조정하고 (0에서 1 사이), 셔플 링하고. 한 번에 하나의 미니 배치를 로드하는 간단한 함수를 제공하니 이용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실행하려는 에포크의 수와 미니 배치의 크기를 정의하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습을 시키자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 코드는 TensorFlow 세션을 열고 모든 변수를 초기화하는 init 노드를 실행한다. 그런 다음 기본 학습 루프를 실행한다. \n",
    "- 각 에포크마다 코드는 학습 데이터 세트 크기에 해당하는 미니 배치를 반복 수행 한다. \n",
    "- 각 미니 배치는 next_batch () 메소드를 통해 가져오고 코드는 학습 작업을 실행하면서, 현재 미니 배치 입력 데이터와 target을 제공한다.\n",
    "- 다음으로, 마지막 에포크에서, 코드는 마지막 미니 배치와 전체 학습 세트에서 모델을 평가하고 결과를 출력한다.\n",
    "- 마지막으로 모델 매개 변수가 디스크에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.9128\n",
      "1 Train accuracy: 0.94 Test accuracy: 0.9291\n",
      "2 Train accuracy: 0.92 Test accuracy: 0.9398\n",
      "3 Train accuracy: 0.96 Test accuracy: 0.9449\n",
      "4 Train accuracy: 0.92 Test accuracy: 0.9511\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.9542\n",
      "6 Train accuracy: 0.98 Test accuracy: 0.9556\n",
      "7 Train accuracy: 0.96 Test accuracy: 0.9594\n",
      "8 Train accuracy: 0.92 Test accuracy: 0.9627\n",
      "9 Train accuracy: 0.96 Test accuracy: 0.9647\n",
      "10 Train accuracy: 0.98 Test accuracy: 0.965\n",
      "11 Train accuracy: 0.94 Test accuracy: 0.9669\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.969\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9684\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.9699\n",
      "15 Train accuracy: 1.0 Test accuracy: 0.9714\n",
      "16 Train accuracy: 1.0 Test accuracy: 0.9713\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9714\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.973\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.9731\n",
      "20 Train accuracy: 0.98 Test accuracy: 0.9736\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.974\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.9744\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.9748\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.9751\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.9757\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.9751\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.976\n",
      "28 Train accuracy: 0.98 Test accuracy: 0.9759\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.9763\n",
      "30 Train accuracy: 1.0 Test accuracy: 0.9764\n",
      "31 Train accuracy: 1.0 Test accuracy: 0.9768\n",
      "32 Train accuracy: 0.98 Test accuracy: 0.9764\n",
      "33 Train accuracy: 0.98 Test accuracy: 0.9766\n",
      "34 Train accuracy: 0.98 Test accuracy: 0.9786\n",
      "35 Train accuracy: 0.98 Test accuracy: 0.9776\n",
      "36 Train accuracy: 0.98 Test accuracy: 0.977\n",
      "37 Train accuracy: 1.0 Test accuracy: 0.9785\n",
      "38 Train accuracy: 1.0 Test accuracy: 0.9786\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                            y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Neural Network\n",
    "- nn을 학습시켰으니, 이제 예측하는데 써먹어보자\n",
    "- 동일한 구성 단계를 재사용 할 수 있지만, 다음과 같이 실행 단계 아래와 같이 변경시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = mnist.test.images[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 디스크에서 모델 매개 변수를 로드하자.\n",
    "- 그런 다음 분류 할 새 이미지를로드합니다. \n",
    "- 교육 데이터의 경우와 feature scaling 을 적용해야 한다. (이 경우 크기를 0에서 1로 조정). 그런 다음 코드는 logits 노드를 평가합니다. \n",
    "- 모든 예상 클래스 확률을 알고 싶다면 softmax () 함수를 logits에 적용해야하지만,\n",
    " - argmax () 함수를 수행함으로써 클래스를 예측하려는 경우 가장 높은 logit 값을 가진 클래스를 선택할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Actual classes:   \", mnist.test.labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.2851015593374667&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0714285746216774\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;dnn/hidden1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;dnn/hidden1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;dnn/hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;dnn/hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.1154700517654419\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 21\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;dnn/hidden2/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;dnn/hidden2/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;dnn/hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;dnn/hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 37\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;dnn/outputs/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;dnn/outputs/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;dnn/outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;dnn/outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 300\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Sum_1&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_dnn/outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_dnn/outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/add&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/accuracy/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;eval/accuracy&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/accuracy&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;eval/accuracy/tags&quot;\\n  input: &quot;eval/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^dnn/hidden1/kernel/Assign&quot;\\n  input: &quot;^dnn/hidden1/bias/Assign&quot;\\n  input: &quot;^dnn/hidden2/kernel/Assign&quot;\\n  input: &quot;^dnn/hidden2/bias/Assign&quot;\\n  input: &quot;^dnn/outputs/kernel/Assign&quot;\\n  input: &quot;^dnn/outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/bias&quot;\\n        string_val: &quot;dnn/hidden1/kernel&quot;\\n        string_val: &quot;dnn/hidden2/bias&quot;\\n        string_val: &quot;dnn/hidden2/kernel&quot;\\n        string_val: &quot;dnn/outputs/bias&quot;\\n        string_val: &quot;dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.2851015593374667&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters\n",
    "- randomized search\n",
    "- Oscar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Number of Hidden Layers\n",
    "- 깊은 네트워크는 얕은 네트워크보다 파라미터 효율성이 훨씬 높다. 얕은 네트워크보다 지수 함수 적으로 더 적은 뉴런을 사용하여 복잡한 함수를 모델링 할 수 있으므로 학습이 훨씬 빨라졌습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Neurons per Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using dense() instead of neuron_layer()\n",
    "Note: the book uses tensorflow.contrib.layers.fully_connected() rather than tf.layers.dense() (which did not exist when this chapter was written). It is now preferable to use tf.layers.dense(), because anything in the contrib module may change or be deleted without notice. The dense() function is almost identical to the fully_connected() function, except for a few minor differences:\n",
    "several parameters are renamed: scope becomes name, activation_fn becomes activation (and similarly the _fn suffix is removed from other parameters such as normalizer_fn), weights_initializer becomes kernel_initializer, etc.\n",
    "the default activation is now None rather than tf.nn.relu.\n",
    "a few more differences are presented in chapter 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.9053\n",
      "1 Train accuracy: 0.88 Test accuracy: 0.9207\n",
      "2 Train accuracy: 0.94 Test accuracy: 0.9299\n",
      "3 Train accuracy: 0.94 Test accuracy: 0.9399\n",
      "4 Train accuracy: 0.92 Test accuracy: 0.9452\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.9475\n",
      "6 Train accuracy: 0.92 Test accuracy: 0.9516\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.9547\n",
      "8 Train accuracy: 0.96 Test accuracy: 0.9569\n",
      "9 Train accuracy: 0.94 Test accuracy: 0.9605\n",
      "10 Train accuracy: 0.92 Test accuracy: 0.9619\n",
      "11 Train accuracy: 0.96 Test accuracy: 0.9631\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.9659\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9657\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.9669\n",
      "15 Train accuracy: 0.94 Test accuracy: 0.9682\n",
      "16 Train accuracy: 0.96 Test accuracy: 0.9701\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9696\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.9699\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.9709\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "n_batches = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.7224827313584268&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.7224827313584268&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
